<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Rust Std Mutex vs Tokio Mutex | just some developer thoughts</title><meta name=keywords content="rust"><meta name=description content="My last post was about benchmarking mutexes and actor model. I was wondering what&rsquo;s a faster way to synchronize state and conclusion of my findings was that mutexes are 2-3 times faster depending on the exact Actor implementation. There was one underlying assumption that I didn&rsquo;t specify explicitly in those benchmarks - I was using Tokio implementation of mutexes. Tokio mutexes are slower than their Std counterpart, so why would anyone pick them."><meta name=author content><link rel=canonical href=https://nxyt.pl/blog/posts/rust_std_tokio_mutex/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://nxyt.pl/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://nxyt.pl/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://nxyt.pl/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://nxyt.pl/blog/apple-touch-icon.png><link rel=mask-icon href=https://nxyt.pl/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-D4BXHY930J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D4BXHY930J",{anonymize_ip:!1})}</script><meta property="og:title" content="Rust Std Mutex vs Tokio Mutex"><meta property="og:description" content="My last post was about benchmarking mutexes and actor model. I was wondering what&rsquo;s a faster way to synchronize state and conclusion of my findings was that mutexes are 2-3 times faster depending on the exact Actor implementation. There was one underlying assumption that I didn&rsquo;t specify explicitly in those benchmarks - I was using Tokio implementation of mutexes. Tokio mutexes are slower than their Std counterpart, so why would anyone pick them."><meta property="og:type" content="article"><meta property="og:url" content="https://nxyt.pl/blog/posts/rust_std_tokio_mutex/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-08T00:00:00+00:00"><meta property="article:modified_time" content="2024-03-08T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Rust Std Mutex vs Tokio Mutex"><meta name=twitter:description content="My last post was about benchmarking mutexes and actor model. I was wondering what&rsquo;s a faster way to synchronize state and conclusion of my findings was that mutexes are 2-3 times faster depending on the exact Actor implementation. There was one underlying assumption that I didn&rsquo;t specify explicitly in those benchmarks - I was using Tokio implementation of mutexes. Tokio mutexes are slower than their Std counterpart, so why would anyone pick them."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://nxyt.pl/blog/posts/"},{"@type":"ListItem","position":3,"name":"Rust Std Mutex vs Tokio Mutex","item":"https://nxyt.pl/blog/posts/rust_std_tokio_mutex/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Rust Std Mutex vs Tokio Mutex","name":"Rust Std Mutex vs Tokio Mutex","description":"My last post was about benchmarking mutexes and actor model. I was wondering what\u0026rsquo;s a faster way to synchronize state and conclusion of my findings was that mutexes are 2-3 times faster depending on the exact Actor implementation. There was one underlying assumption that I didn\u0026rsquo;t specify explicitly in those benchmarks - I was using Tokio implementation of mutexes. Tokio mutexes are slower than their Std counterpart, so why would anyone pick them.","keywords":["rust"],"articleBody":"My last post was about benchmarking mutexes and actor model. I was wondering what’s a faster way to synchronize state and conclusion of my findings was that mutexes are 2-3 times faster depending on the exact Actor implementation. There was one underlying assumption that I didn’t specify explicitly in those benchmarks - I was using Tokio implementation of mutexes. Tokio mutexes are slower than their Std counterpart, so why would anyone pick them.\nStd Mutex vs Tokio Mutex What’s the difference between them? Std mutex is built for sharing values between OS threads. Tokio is async runtime and their Mutex implementation is used to share values between tasks (green threads). That means that Std mutex is ‘simpler’ and more performant as Tokio has to account for switching context not just between OS threads but also their internal abstraction (tasks).\nOne result of those architectural differences is that Std mutexes cannot be held across ‘await’, but even in async environment we often don’t need to do that. Very often mutexes are just guarding value for X amount of time. If you’re locking some value just to access/modify it, then chances are that std mutex will be more performant than tokio mutex.\nWhen to use Std Mutex and when to use Tokio Mutex If Tokio mutex is slower, why would you use it? Huge advantage of Tokio mutexes is the fact that Tokio runtime can do another work while waiting for the lock. Depending on your application and amount of OS threads your machine can offer to your program (tokio by default spawns one thread per cpu core), if you’re locking values behind std mutex, then nothing else will run on that thread until mutex can be acquired. That means this thread will not participate in other work and instead will sit idle. If your program is composed of many services, that could potentially mean that one service locking mutex is introducing latency to unrelated service. Typical latency vs throughput problem.\nBecause of this despite lower performance Tokio mutexes are good default in async environments as they tend to scale with async software complexity a little bit better.\nBenchmark I’m reusing the same benchmark that I’ve created to test Tokio mutex vs Actor model. Essentially I’ve struct with some value and 100_000 concurrent async futures try to modify this value. One implementation is using Std mutex and one is using Tokio mutex. What we’re effectively measuring here is overhead of tokio mutexes in environment where there’s no other work in the background.\nCode Here’s simplified code we’ll be benchmarking\n#[derive(Default)] pub struct BenchStruct { /// in reality there are two variants of BenchStruct one with std mutex one with tokio mutex count: Mutex\u003ci64\u003e, } ... /// and we have two sets of methods one for std mutex and one for tokio mutex /// tokio mutex pub async fn increase_by(\u0026self, i: i64) { (*self.count.lock().await) += i; } /// std mutex pub async fn increase_by(\u0026self, i: i64) { *self.count.lock().unwrap() += i; } And here is benchmarking code\nfn benchmark_mutexes(c: \u0026mut Criterion) { let mut group = c.benchmark_group(\"std mutex vs tokio mutex\"); group.bench_function(\"tokio mutex\", |b| { b.to_async(Runtime::new().unwrap()).iter(|| async { let mutex = Arc::new(BenchMutex::default()); let bench_tasks = iter_range .map(|_| { let m_copy = mutex.clone(); async move { m_copy.increase_by(2).await; m_copy.decrease_by(0).await; } }) .collect::\u003cVec\u003c_\u003e\u003e(); join_all(bench_tasks).await; assert_eq!(mutex.get().await, REACHED_COUNT_SIGNAL_AMOUNT); }); }); group.bench_function(\"std mutex\", |b| { b.to_async(Runtime::new().unwrap()).iter(|| async { let mutex = Arc::new(BenchStdMutex::default()); let bench_tasks = iter_range .map(|_| { let m_copy = mutex.clone(); async move { m_copy.increase_by(2).await; m_copy.decrease_by(0).await; } }) .collect::\u003cVec\u003c_\u003e\u003e(); join_all(bench_tasks).await; assert_eq!(mutex.get().await, REACHED_COUNT_SIGNAL_AMOUNT); }); }); group.finish(); } iter_range is set to 100_000 so we’re making 100_000 concurrent futures each trying to access the lock twice.\nResults std mutex vs tokio mutex/tokio mutex time: [16.158 ms 16.223 ms 16.303 ms] change: [-49.342% -48.930% -48.440%] (p = 0.00 \u003c 0.05) std mutex vs tokio mutex/std mutex time: [7.2295 ms 7.2521 ms 7.2780 ms] change: [+4.3129% +4.8652% +5.4262%] (p = 0.00 \u003c 0.05) Performance varies between runs, but generally std mutexes tend to be 2x faster on my machine. I think this just goes to show that tokio mutexes are good enough and I’d personally go with them as my first choice until they become performance bottleneck (personally I’ve never encountered such situation).\nAdditional notes tokio mutexes obviously poison functions with async, so they’re only used in async environment std mutexes can be used in both sync and async environments, but they poison functions with Results\u003c\u003e (locking std mutex returns Result) if you’re sure that lock is held only for very short amount of time std mutex will be faster even in async environment despite point above tokio mutex is still very performant and good enaugh Summary In my last Actor vs Mutex benchmark mutexes were 2-3 times faster, std mutexes can increase the gap to 4-6 times the performance of Actor model. This just goes to show how good synchronization mechanism they are. I really those quick benchmarks as they help me better understand alternatives I can pick between for each task. I hope you’ve found results of this benchmark useful. Have a great day :-)\n","wordCount":"844","inLanguage":"en","datePublished":"2024-03-08T00:00:00Z","dateModified":"2024-03-08T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://nxyt.pl/blog/posts/rust_std_tokio_mutex/"},"publisher":{"@type":"Organization","name":"just some developer thoughts","logo":{"@type":"ImageObject","url":"https://nxyt.pl/blog/favicon.ico"}}}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-D4BXHY930J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D4BXHY930J",{anonymize_ip:!1})}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nxyt.pl/blog accesskey=h title="just some developer thoughts (Alt + H)">just some developer thoughts</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Rust Std Mutex vs Tokio Mutex</h1><div class=post-meta><span title='2024-03-08 00:00:00 +0000 UTC'>March 8, 2024</span></div></header><div class=post-content><p>My last post was about benchmarking mutexes and actor model. I was wondering what&rsquo;s a faster way to synchronize state and conclusion of my
findings was that mutexes are 2-3 times faster depending on the exact Actor implementation. There was one underlying assumption that I didn&rsquo;t specify
explicitly in those benchmarks - I was using Tokio implementation of mutexes. Tokio mutexes are slower than their Std counterpart, so why would anyone pick them.</p><h1 id=std-mutex-vs-tokio-mutex>Std Mutex vs Tokio Mutex<a hidden class=anchor aria-hidden=true href=#std-mutex-vs-tokio-mutex>#</a></h1><p>What&rsquo;s the difference between them? Std mutex is built for sharing values between OS threads. Tokio is async runtime and their Mutex implementation is
used to share values between tasks (green threads). That means that Std mutex is &lsquo;simpler&rsquo; and more performant as Tokio has to account for switching context
not just between OS threads but also their internal abstraction (tasks).</p><p>One result of those architectural differences is that Std mutexes cannot be held across &lsquo;await&rsquo;, but even in async environment we often don&rsquo;t need to do that.
Very often mutexes are just guarding value for X amount of time. If you&rsquo;re locking some value just to access/modify it, then chances are that std mutex will
be more performant than tokio mutex.</p><h1 id=when-to-use-std-mutex-and-when-to-use-tokio-mutex>When to use Std Mutex and when to use Tokio Mutex<a hidden class=anchor aria-hidden=true href=#when-to-use-std-mutex-and-when-to-use-tokio-mutex>#</a></h1><p>If Tokio mutex is slower, why would you use it? Huge advantage of Tokio mutexes is the fact that Tokio runtime can do another work while waiting for the lock.
Depending on your application and amount of OS threads your machine can offer to your program (tokio by default spawns one thread per cpu core),
if you&rsquo;re locking values behind std mutex, then nothing else will run on that thread until mutex can be acquired.
That means this thread will not participate in other work and instead will sit idle. If your program is composed of many services, that could potentially mean
that one service locking mutex is introducing latency to unrelated service. Typical latency vs throughput problem.</p><p>Because of this despite lower performance Tokio mutexes are good default in async environments as they tend to scale with async software complexity a little bit better.</p><h1 id=benchmark>Benchmark<a hidden class=anchor aria-hidden=true href=#benchmark>#</a></h1><p>I&rsquo;m reusing the same benchmark that I&rsquo;ve created to test Tokio mutex vs Actor model. Essentially I&rsquo;ve struct with some value and 100_000 concurrent async futures try
to modify this value. One implementation is using Std mutex and one is using Tokio mutex. What we&rsquo;re effectively measuring here is overhead of tokio mutexes in environment where there&rsquo;s no other work in the background.</p><h2 id=code>Code<a hidden class=anchor aria-hidden=true href=#code>#</a></h2><p>Here&rsquo;s simplified code we&rsquo;ll be benchmarking</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rs data-lang=rs><span style=display:flex><span><span style=color:#75715e>#[derive(Default)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>BenchStruct</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>/// in reality there are two variants of BenchStruct one with std mutex one with tokio mutex
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span>    count: <span style=color:#a6e22e>Mutex</span><span style=color:#f92672>&lt;</span><span style=color:#66d9ef>i64</span><span style=color:#f92672>&gt;</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#f92672>..</span>.
</span></span><span style=display:flex><span><span style=color:#e6db74>/// and we have two sets of methods one for std mutex and one for tokio mutex 
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span>
</span></span><span style=display:flex><span><span style=color:#e6db74>/// tokio mutex
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>increase_by</span>(<span style=color:#f92672>&amp;</span>self, i: <span style=color:#66d9ef>i64</span>) {
</span></span><span style=display:flex><span>  (<span style=color:#f92672>*</span>self.count.lock().<span style=color:#66d9ef>await</span>) <span style=color:#f92672>+=</span> i;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#e6db74>/// std mutex
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>increase_by</span>(<span style=color:#f92672>&amp;</span>self, i: <span style=color:#66d9ef>i64</span>) {
</span></span><span style=display:flex><span>    <span style=color:#f92672>*</span>self.count.lock().unwrap() <span style=color:#f92672>+=</span> i;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>And here is benchmarking code</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rs data-lang=rs><span style=display:flex><span><span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>benchmark_mutexes</span>(c: <span style=color:#66d9ef>&amp;</span><span style=color:#a6e22e>mut</span> Criterion) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> group <span style=color:#f92672>=</span> c.benchmark_group(<span style=color:#e6db74>&#34;std mutex vs tokio mutex&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    group.bench_function(<span style=color:#e6db74>&#34;tokio mutex&#34;</span>, <span style=color:#f92672>|</span>b<span style=color:#f92672>|</span> {
</span></span><span style=display:flex><span>        b.to_async(Runtime::new().unwrap()).iter(<span style=color:#f92672>||</span> <span style=color:#66d9ef>async</span> {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> mutex <span style=color:#f92672>=</span> Arc::new(BenchMutex::default());
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> bench_tasks <span style=color:#f92672>=</span> iter_range
</span></span><span style=display:flex><span>                .map(<span style=color:#f92672>|</span>_<span style=color:#f92672>|</span> {
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>let</span> m_copy <span style=color:#f92672>=</span> mutex.clone();
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>move</span> {
</span></span><span style=display:flex><span>                        m_copy.increase_by(<span style=color:#ae81ff>2</span>).<span style=color:#66d9ef>await</span>;
</span></span><span style=display:flex><span>                        m_copy.decrease_by(<span style=color:#ae81ff>0</span>).<span style=color:#66d9ef>await</span>;
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                })
</span></span><span style=display:flex><span>                .collect::<span style=color:#f92672>&lt;</span>Vec<span style=color:#f92672>&lt;</span>_<span style=color:#f92672>&gt;&gt;</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            join_all(bench_tasks).<span style=color:#66d9ef>await</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            assert_eq!(mutex.get().<span style=color:#66d9ef>await</span>, REACHED_COUNT_SIGNAL_AMOUNT);
</span></span><span style=display:flex><span>        });
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    group.bench_function(<span style=color:#e6db74>&#34;std mutex&#34;</span>, <span style=color:#f92672>|</span>b<span style=color:#f92672>|</span> {
</span></span><span style=display:flex><span>        b.to_async(Runtime::new().unwrap()).iter(<span style=color:#f92672>||</span> <span style=color:#66d9ef>async</span> {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> mutex <span style=color:#f92672>=</span> Arc::new(BenchStdMutex::default());
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> bench_tasks <span style=color:#f92672>=</span> iter_range
</span></span><span style=display:flex><span>                .map(<span style=color:#f92672>|</span>_<span style=color:#f92672>|</span> {
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>let</span> m_copy <span style=color:#f92672>=</span> mutex.clone();
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>move</span> {
</span></span><span style=display:flex><span>                        m_copy.increase_by(<span style=color:#ae81ff>2</span>).<span style=color:#66d9ef>await</span>;
</span></span><span style=display:flex><span>                        m_copy.decrease_by(<span style=color:#ae81ff>0</span>).<span style=color:#66d9ef>await</span>;
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                })
</span></span><span style=display:flex><span>                .collect::<span style=color:#f92672>&lt;</span>Vec<span style=color:#f92672>&lt;</span>_<span style=color:#f92672>&gt;&gt;</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            join_all(bench_tasks).<span style=color:#66d9ef>await</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            assert_eq!(mutex.get().<span style=color:#66d9ef>await</span>, REACHED_COUNT_SIGNAL_AMOUNT);
</span></span><span style=display:flex><span>        });
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    group.finish();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>iter_range is set to 100_000 so we&rsquo;re making 100_000 concurrent futures each trying to access the lock twice.</p><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><pre tabindex=0><code>std mutex vs tokio mutex/tokio mutex
                        time:   [16.158 ms 16.223 ms 16.303 ms]
                        change: [-49.342% -48.930% -48.440%] (p = 0.00 &lt; 0.05)
std mutex vs tokio mutex/std mutex
                        time:   [7.2295 ms 7.2521 ms 7.2780 ms]
                        change: [+4.3129% +4.8652% +5.4262%] (p = 0.00 &lt; 0.05)
</code></pre><p>Performance varies between runs, but generally std mutexes tend to be 2x faster on my machine. I think this just goes to show that tokio mutexes are good enough and
I&rsquo;d personally go with them as my first choice until they become performance bottleneck (personally I&rsquo;ve never encountered such situation).</p><h3 id=additional-notes>Additional notes<a hidden class=anchor aria-hidden=true href=#additional-notes>#</a></h3><ul><li>tokio mutexes obviously poison functions with async, so they&rsquo;re only used in async environment</li><li>std mutexes can be used in both sync and async environments, but they poison functions with Results&lt;> (locking std mutex returns Result)</li><li>if you&rsquo;re sure that lock is held only for very short amount of time std mutex will be faster even in async environment</li><li>despite point above tokio mutex is still very performant and good enaugh</li></ul><h1 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h1><p>In my last Actor vs Mutex benchmark mutexes were 2-3 times faster, std mutexes can increase the gap to 4-6 times the performance of Actor model. This just
goes to show how good synchronization mechanism they are. I really those quick benchmarks as they help me better understand alternatives I can pick between for
each task. I hope you&rsquo;ve found results of this benchmark useful. Have a great day :-)</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://nxyt.pl/blog/tags/rust/>rust</a></li></ul></footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//nxyt.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2024 <a href=https://nxyt.pl/blog>just some developer thoughts</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>